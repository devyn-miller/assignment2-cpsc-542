{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no horizontal flips\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)\n",
    "\n",
    "\n",
    "def normalize(input_image, input_mask):\n",
    "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "  input_mask -= 1\n",
    "  return input_image, input_mask\n",
    "\n",
    "def load_image(datapoint):\n",
    "  input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
    "  input_mask = tf.image.resize(\n",
    "    datapoint['segmentation_mask'],\n",
    "    (128, 128),\n",
    "    method = tf.image.ResizeMethod.NEAREST_NEIGHBOR,\n",
    "  )\n",
    "\n",
    "  input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "  return input_image, input_mask\n",
    "\n",
    "\"\"\"The dataset already contains the required training and test splits, so continue to use the same splits:\"\"\"\n",
    "\n",
    "TRAIN_LENGTH = info.splits['train'].num_examples\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 1000\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
    "\n",
    "train_images = dataset['train'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_images = dataset['test'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "\"\"\"The following class performs a simple augmentation by randomly-flipping an image.\n",
    "Go to the [Image augmentation](data_augmentation.ipynb) tutorial to learn more.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class Augment(tf.keras.layers.Layer):\n",
    "  def __init__(self, seed=42):\n",
    "    super().__init__()\n",
    "    # both use the same seed, so they'll make the same random changes.\n",
    "    # self.augment_inputs = tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=seed)\n",
    "    # self.augment_labels = tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=seed)\n",
    "\n",
    "  def call(self, inputs, labels):\n",
    "    # inputs = self.augment_inputs(inputs)\n",
    "    # labels = self.augment_labels(labels)\n",
    "    return inputs, labels\n",
    "\n",
    "\"\"\"Build the input pipeline, applying the augmentation after batching the inputs:\"\"\"\n",
    "\n",
    "train_batches = (\n",
    "    train_images\n",
    "    .cache()\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .repeat()\n",
    "    .map(Augment())\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "\n",
    "test_batches = test_images.batch(BATCH_SIZE)\n",
    "\n",
    "\"\"\"Visualize an image example and its corresponding mask from the dataset:\"\"\"\n",
    "\n",
    "def display(display_list):\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "for images, masks in train_batches.take(2):\n",
    "  sample_image, sample_mask = images[0], masks[0]\n",
    "  display([sample_image, sample_mask])\n",
    "\n",
    "\"\"\"## Define the model\n",
    "The model being used here is a modified [U-Net](https://arxiv.org/abs/1505.04597). A U-Net consists of an encoder (downsampler) and decoder (upsampler). To learn robust features and reduce the number of trainable parameters, use a pretrained model—[MobileNetV2](https://arxiv.org/abs/1801.04381)—as the encoder. For the decoder, you will use the upsample block, which is already implemented in the [pix2pix](https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/pix2pix/pix2pix.py) example in the TensorFlow Examples repo. (Check out the [pix2pix: Image-to-image translation with a conditional GAN](../generative/pix2pix.ipynb) tutorial in a notebook.)\n",
    "\n",
    "As mentioned, the encoder is a pretrained MobileNetV2 model. You will use the model from `tf.keras.applications`. The encoder consists of specific outputs from intermediate layers in the model. Note that the encoder will not be trained during the training process.\n",
    "\"\"\"\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n",
    "\n",
    "# Use the activations of these layers\n",
    "layer_names = [\n",
    "    'block_1_expand_relu',   # 64x64\n",
    "    'block_3_expand_relu',   # 32x32\n",
    "    'block_6_expand_relu',   # 16x16\n",
    "    'block_13_expand_relu',  # 8x8\n",
    "    'block_16_project',      # 4x4\n",
    "]\n",
    "base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n",
    "\n",
    "# Create the feature extraction model\n",
    "down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n",
    "\n",
    "down_stack.trainable = False\n",
    "\n",
    "\"\"\"The decoder/upsampler is simply a series of upsample blocks implemented in TensorFlow examples:\"\"\"\n",
    "\n",
    "up_stack = [\n",
    "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
    "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
    "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
    "    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
    "]\n",
    "\n",
    "def unet_model(output_channels:int):\n",
    "    inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n",
    "\n",
    "    # Downsampling through the model\n",
    "    x = inputs\n",
    "    skips = []\n",
    "    for filter_size in [64, 128, 256, 512]:\n",
    "        x = tf.keras.layers.Conv2D(filter_size, 3, padding='same', activation='relu', kernel_initializer='he_normal')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Conv2D(filter_size, 3, padding='same', activation='relu', kernel_initializer='he_normal')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        skips.append(x)\n",
    "        x = tf.keras.layers.MaxPooling2D(2)(x)\n",
    "        x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "    # Middle part of the network\n",
    "    x = tf.keras.layers.Conv2D(1024, 3, padding='same', activation='relu', kernel_initializer='he_normal')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(1024, 3, padding='same', activation='relu', kernel_initializer='he_normal')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    skips = reversed(skips)\n",
    "    for filter_size, skip in zip([512, 256, 128, 64], skips):\n",
    "        x = tf.keras.layers.Conv2DTranspose(filter_size, 2, strides=2, padding='same')(x)\n",
    "        concat = tf.keras.layers.Concatenate()\n",
    "        x = concat([x, skip])\n",
    "        x = tf.keras.layers.Conv2D(filter_size, 3, padding='same', activation='relu', kernel_initializer='he_normal')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Conv2D(filter_size, 3, padding='same', activation='relu', kernel_initializer='he_normal')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    # This is the last layer of the model\n",
    "    last = tf.keras.layers.Conv2D(output_channels, 3, padding='same')  # Maintain 128x128 resolution\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "\"\"\"Note that the number of filters on the last layer is set to the number of `output_channels`. This will be one output channel per class.\n",
    "\n",
    "## Train the model\n",
    "\n",
    "Now, all that is left to do is to compile and train the model.\n",
    "\n",
    "Since this is a multiclass classification problem, use the `tf.keras.losses.SparseCategoricalCrossentropy` loss function with the `from_logits` argument set to `True`, since the labels are scalar integers instead of vectors of scores for each pixel of every class.\n",
    "\n",
    "When running inference, the label assigned to the pixel is the channel with the highest value. This is what the `create_mask` function is doing.\n",
    "\"\"\"\n",
    "\n",
    "OUTPUT_CLASSES = 3\n",
    "\n",
    "model = unet_model(output_channels=OUTPUT_CLASSES)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\"\"\"Plot the resulting model architecture:\"\"\"\n",
    "\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)\n",
    "\n",
    "\"\"\"Try out the model to check what it predicts before training:\"\"\"\n",
    "\n",
    "def create_mask(pred_mask):\n",
    "  pred_mask = tf.math.argmax(pred_mask, axis=-1)\n",
    "  pred_mask = pred_mask[..., tf.newaxis]\n",
    "  return pred_mask[0]\n",
    "\n",
    "def show_predictions(dataset=None, num=1):\n",
    "  if dataset:\n",
    "    for image, mask in dataset.take(num):\n",
    "      pred_mask = model.predict(image)\n",
    "      display([image[0], mask[0], create_mask(pred_mask)])\n",
    "  else:\n",
    "    display([sample_image, sample_mask,\n",
    "             create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n",
    "\n",
    "show_predictions()\n",
    "\n",
    "\"\"\"The callback defined below is used to observe how the model improves while it is training:\"\"\"\n",
    "\n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    clear_output(wait=True)\n",
    "    show_predictions()\n",
    "    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
    "\n",
    "EPOCHS = 50\n",
    "VAL_SUBSPLITS = 5\n",
    "VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n",
    "\n",
    "model_history = model.fit(train_batches, epochs=EPOCHS,\n",
    "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                          validation_steps=VALIDATION_STEPS,\n",
    "                          validation_data=test_batches,\n",
    "                          callbacks=[DisplayCallback()])\n",
    "\n",
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(model_history.epoch, loss, 'r', label='Training loss')\n",
    "plt.plot(model_history.epoch, val_loss, 'bo', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"## Make predictions\n",
    "\n",
    "Now, make some predictions. In the interest of saving time, the number of epochs was kept small, but you may set this higher to achieve more accurate results.\n",
    "\"\"\"\n",
    "\n",
    "show_predictions(test_batches, 3)\n",
    "\n",
    "\"\"\"## Optional: Imbalanced classes and class weights\n",
    "\n",
    "Semantic segmentation datasets can be highly imbalanced meaning that particular class pixels can be present more inside images than that of other classes. Since segmentation problems can be treated as per-pixel classification problems, you can deal with the imbalance problem by weighing the loss function to account for this. It's a simple and elegant way to deal with this problem. Refer to the [Classification on imbalanced data](../structured_data/imbalanced_data.ipynb) tutorial to learn more.\n",
    "\n",
    "To [avoid ambiguity](https://github.com/keras-team/keras/issues/3653#issuecomment-243939748), `Model.fit` does not support the `class_weight` argument for targets with 3+ dimensions.\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "  model_history = model.fit(train_batches, epochs=EPOCHS,\n",
    "                            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                            class_weight = {0:2.0, 1:2.0, 2:1.0})\n",
    "  assert False\n",
    "except Exception as e:\n",
    "  print(f\"Expected {type(e).__name__}: {e}\")\n",
    "\n",
    "\"\"\"So, in this case you need to implement the weighting yourself. You'll do this using sample weights: In addition to `(data, label)` pairs, `Model.fit` also accepts `(data, label, sample_weight)` triples.\n",
    "\n",
    "Keras `Model.fit` propagates the `sample_weight` to the losses and metrics, which also accept a `sample_weight` argument. The sample weight is multiplied by the sample's value before the reduction step. For example:\n",
    "\"\"\"\n",
    "\n",
    "# label = [0,0]\n",
    "# prediction = [[-3., 0], [-3, 0]]\n",
    "# sample_weight = [1, 10]\n",
    "\n",
    "# loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
    "#                                                reduction=tf.keras.losses.Reduction.NONE)\n",
    "# loss(label, prediction, sample_weight).numpy()\n",
    "\n",
    "# \"\"\"So, to make sample weights for this tutorial, you need a function that takes a `(data, label)` pair and returns a `(data, label, sample_weight)` triple where the `sample_weight` is a 1-channel image containing the class weight for each pixel.\n",
    "\n",
    "# The simplest possible implementation is to use the label as an index into a `class_weight` list:\n",
    "# \"\"\"\n",
    "\n",
    "# def add_sample_weights(image, label):\n",
    "#   # The weights for each class, with the constraint that:\n",
    "#   #     sum(class_weights) == 1.0\n",
    "#   class_weights = tf.constant([2.0, 2.0, 1.0])\n",
    "#   class_weights = class_weights/tf.reduce_sum(class_weights)\n",
    "\n",
    "#   # Create an image of `sample_weights` by using the label at each pixel as an\n",
    "#   # index into the `class weights` .\n",
    "#   sample_weights = tf.gather(class_weights, indices=tf.cast(label, tf.int32))\n",
    "\n",
    "#   return image, label, sample_weights\n",
    "\n",
    "# \"\"\"The resulting dataset elements contain 3 images each:\"\"\"\n",
    "\n",
    "# train_batches.map(add_sample_weights).element_spec\n",
    "\n",
    "# \"\"\"Now, you can train a model on this weighted dataset:\"\"\"\n",
    "\n",
    "# weighted_model = unet_model(OUTPUT_CLASSES)\n",
    "# weighted_model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     metrics=['accuracy'])\n",
    "\n",
    "# weighted_model.fit(\n",
    "#     train_batches.map(add_sample_weights),\n",
    "#     epochs=1,\n",
    "#     steps_per_epoch=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "label = [0, 0]\n",
    "prediction = [[-3., 0], [-3, 0]]\n",
    "sample_weight = [1, 10]\n",
    "\n",
    "# Convert lists to tensors\n",
    "label_tensor = tf.constant(label)\n",
    "prediction_tensor = tf.constant(prediction)\n",
    "sample_weight_tensor = tf.constant(sample_weight)\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
    "                                                     reduction=tf.keras.losses.Reduction.NONE)\n",
    "# Use tensors instead of lists\n",
    "loss_value = loss(label_tensor, prediction_tensor, sample_weight_tensor).numpy()\n",
    "print(loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "def evaluate_model(model, test_dataset):\n",
    "    loss, accuracy = model.evaluate(test_dataset)\n",
    "    print(f'Loss: {loss}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "\n",
    "    # Generate predictions\n",
    "    y_true = np.array([])\n",
    "    y_pred = np.array([])\n",
    "    for datapoint in test_dataset.unbatch().batch(1).take(-1):\n",
    "        image, mask = datapoint\n",
    "        pred_mask = model.predict(image)\n",
    "        y_true = np.append(y_true, mask.numpy().flatten())\n",
    "        y_pred = np.append(y_pred, np.argmax(pred_mask, axis=-1).flatten())\n",
    "\n",
    "    # Calculate metrics\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    iou = tf.keras.metrics.MeanIoU(num_classes=3)\n",
    "    iou.update_state(y_true, y_pred)\n",
    "    iou_score = iou.result().numpy()\n",
    "\n",
    "    # Print metrics\n",
    "    print(f'Confusion Matrix:\\n{conf_mat}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print(f'IoU: {iou_score}')\n",
    "\n",
    "    # Plot metrics\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(conf_mat, cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(['Precision', 'Recall', 'F1', 'IoU'], [precision, recall, f1, iou_score])\n",
    "    plt.title('Metrics')\n",
    "    plt.show()\n",
    "\n",
    "# Assuming GradCAM and display_best_worst_images are implemented correctly elsewhere in your code.\n",
    "\n",
    "# Main pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)\n",
    "    train_dataset = dataset['train'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE).batch(32)\n",
    "    test_dataset = dataset['test'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE).batch(32)\n",
    "    model = unet_model(output_channels=OUTPUT_CLASSES)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    history = model.fit(train_dataset, epochs=EPOCHS,\n",
    "                        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                        validation_data=test_dataset,\n",
    "                        validation_steps=VALIDATION_STEPS)\n",
    "    evaluate_model(model, test_dataset)\n",
    "    # Generate Grad-CAM visualizations for a sample image\n",
    "    for image, mask in test_dataset.take(1):\n",
    "        # generate_gradcam(model, image)\n",
    "        pass\n",
    "    # display_best_worst_images(model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy for train and test by epoch\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# plot loss function for train and test by epoch\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(images, titles, cols=3):\n",
    "    \"\"\"Display images with titles in a grid.\"\"\"\n",
    "    assert len(images) == len(titles)\n",
    "    rows = len(images) // cols + int(len(images) % cols > 0)\n",
    "    plt.figure(figsize=(cols * 4, rows * 4))\n",
    "    for i, (image, title) in enumerate(zip(images, titles)):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(image))\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_and_display_best_worst_images(model, dataset, num_images=3):\n",
    "    accuracies = []\n",
    "    images = []\n",
    "    masks = []\n",
    "    predictions = []\n",
    "\n",
    "    # Iterate over the dataset to gather predictions and their true labels\n",
    "    for image_batch, mask_batch in dataset:\n",
    "        pred_mask_batch = model.predict(image_batch)\n",
    "        for image, true_mask, pred_mask in zip(image_batch, mask_batch, pred_mask_batch):\n",
    "            # Calculate accuracy for each prediction\n",
    "            pred_mask_argmax = tf.math.argmax(pred_mask, axis=-1)\n",
    "            accuracy = np.mean(true_mask.numpy().flatten() == pred_mask_argmax.numpy().flatten())\n",
    "            accuracies.append(accuracy)\n",
    "            images.append(image)\n",
    "            masks.append(true_mask)\n",
    "            predictions.append(pred_mask_argmax)\n",
    "\n",
    "    # Sort predictions by accuracy\n",
    "    sorted_indices = np.argsort(accuracies)\n",
    "    best_indices = sorted_indices[-num_images:]\n",
    "    worst_indices = sorted_indices[:num_images]\n",
    "\n",
    "    # Display best predictions\n",
    "    best_images = [images[i] for i in best_indices]\n",
    "    best_titles = [f\"Best {i+1}: Acc={accuracies[i]:.2f}\" for i in best_indices]\n",
    "    display_images(best_images, best_titles)\n",
    "\n",
    "    # Display worst predictions\n",
    "    worst_images = [images[i] for i in worst_indices]\n",
    "    worst_titles = [f\"Worst {i+1}: Acc={accuracies[i]:.2f}\" for i in worst_indices]\n",
    "    display_images(worst_images, worst_titles)\n",
    "\n",
    "# Assuming 'model' is your trained model and 'test_dataset' is your testing dataset\n",
    "evaluate_and_display_best_worst_images(model, test_dataset, num_images=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # Create a model that maps the input image to the activations of the last conv layer\n",
    "    # as well as the output predictions. Ensure model.inputs is correctly passed.\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        inputs=model.inputs,  # Corrected this line\n",
    "        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        print(preds.shape)\n",
    "        # if pred_index is None:\n",
    "        #     pred_index = tf.argmax(preds[0])\n",
    "        #     pred_index = pred_index.numpy()  # Convert to numpy if it's a tensor\n",
    "        #     if isinstance(pred_index, np.ndarray):  # Ensure it's a scalar\n",
    "        #         pred_index = pred_index.item()\n",
    "        pred_index = 0\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with respect to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # Vector of mean intensity of the gradient over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # Multiply each channel in the feature map array by \"how important this channel is\"\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # Normalize the heatmap between 0 & 1 for visualization\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def display_gradcam(img, heatmap, alpha=0.4):\n",
    "    # Load the original image\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'last_conv_layer_name' is the name of the last conv layer in your model\n",
    "last_conv_layer_name = 'conv2d_37'\n",
    "for image, mask in test_dataset.take(1):\n",
    "    img_array = tf.expand_dims(image[0], axis=0)  # Select the first image in the batch\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "    display_gradcam(image[0], heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_display_best_worst_images_with_gradcam(model, dataset, last_conv_layer_name, num_images=3):\n",
    "    accuracies = []\n",
    "    images = []\n",
    "    masks = []\n",
    "    predictions = []\n",
    "\n",
    "    # Iterate over the dataset to gather predictions and their true labels\n",
    "    for image_batch, mask_batch in dataset:\n",
    "        pred_mask_batch = model.predict(image_batch)\n",
    "        for image, true_mask, pred_mask in zip(image_batch, mask_batch, pred_mask_batch):\n",
    "            # Calculate accuracy for each prediction\n",
    "            pred_mask_argmax = tf.math.argmax(pred_mask, axis=-1)\n",
    "            accuracy = np.mean(true_mask.numpy().flatten() == pred_mask_argmax.numpy().flatten())\n",
    "            accuracies.append(accuracy)\n",
    "            images.append(image.numpy())\n",
    "            masks.append(true_mask)\n",
    "            predictions.append(pred_mask_argmax)\n",
    "\n",
    "    # Sort predictions by accuracy\n",
    "    sorted_indices = np.argsort(accuracies)\n",
    "    best_indices = sorted_indices[-num_images:]\n",
    "    worst_indices = sorted_indices[:num_images]\n",
    "\n",
    "    # Prepare to display images and their Grad-CAM heatmaps\n",
    "    selected_images = [images[i] for i in np.concatenate([best_indices, worst_indices])]\n",
    "    selected_titles = [f\"Best {i+1}\" for i in range(num_images)] + [f\"Worst {i+1}\" for i in range(num_images)]\n",
    "\n",
    "    cols = 3\n",
    "    rows = (len(selected_images) // cols) + int(len(selected_images) % cols > 0)\n",
    "    plt.figure(figsize=(cols * 4, rows * 4))\n",
    "\n",
    "    for i, image in enumerate(selected_images):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        img_array = np.expand_dims(image, axis=0)\n",
    "        # Use a fixed pred_index for visualization\n",
    "        pred_index = 0\n",
    "        heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=pred_index)\n",
    "        display_gradcam(image, heatmap)\n",
    "        plt.title(selected_titles[i])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'last_conv_layer_name' is the name of the last conv layer in your model\n",
    "last_conv_layer_name = 'conv2d_37'\n",
    "for image, mask in test_dataset.take(1):\n",
    "    img_array = tf.expand_dims(image[0], axis=0)  # Select the first image in the batch\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "    evaluate_and_display_best_worst_images_with_gradcam(model, test_dataset, last_conv_layer_name, num_images=3)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
